#!/usr/bin/env python3
"""Claude Codeå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from yaml_context_engineering.config import Config
from yaml_context_engineering.tools import (
    WebContentFetcher,
    LLMStructureExtractor,
    URLDiscoveryEngine,
    FileSystemManager
)


async def extract_claude_code_docs():
    """Claude Codeå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰éšå±¤çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       Claude Code ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Claude Codeãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸»è¦URL
    claude_docs_urls = [
        "https://docs.anthropic.com/ja/docs/claude-code/overview",
        "https://docs.anthropic.com/ja/docs/claude-code/quickstart",
        "https://docs.anthropic.com/ja/docs/claude-code/common-workflows",
        "https://docs.anthropic.com/ja/docs/claude-code/mcp",
        "https://docs.anthropic.com/ja/docs/claude-code/sdk",
        "https://docs.anthropic.com/ja/docs/claude-code/hooks",
        "https://docs.anthropic.com/ja/docs/claude-code/github-actions",
        "https://docs.anthropic.com/ja/docs/claude-code/troubleshooting",
        "https://docs.anthropic.com/ja/docs/claude-code/cli-reference",
        "https://docs.anthropic.com/ja/docs/claude-code/interactive-mode",
        "https://docs.anthropic.com/ja/docs/claude-code/slash-commands",
        "https://docs.anthropic.com/ja/docs/claude-code/settings"
    ]
    
    # è¨­å®šã‚’åˆæœŸåŒ–
    config = Config.from_env()
    config.output.output_base_directory = Path("generated_contexts/claude-code-full")
    
    # ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
    fetcher = WebContentFetcher(config)
    extractor = LLMStructureExtractor(config)
    discovery = URLDiscoveryEngine(config)
    file_manager = FileSystemManager(config)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    await file_manager.execute(
        action="create_directory",
        path="",
        content={
            "overview": {},
            "getting-started": {},
            "building": {},
            "deployment": {},
            "administration": {},
            "configuration": {},
            "reference": {},
            "resources": {}
        }
    )
    
    all_contexts = []
    
    try:
        for url in claude_docs_urls:
            print(f"\nğŸ“„ å‡¦ç†ä¸­: {url}")
            print("="*60)
            
            # URLã‹ã‚‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŠ½å‡º
            url_parts = url.split('/')
            section_name = url_parts[-1] if url_parts else 'unknown'
            
            # ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
            if 'overview' in section_name or 'quickstart' in section_name:
                category = 'getting-started'
            elif any(x in section_name for x in ['mcp', 'sdk', 'hooks', 'github']):
                category = 'building'
            elif any(x in section_name for x in ['cli', 'interactive', 'slash', 'commands']):
                category = 'reference'
            elif 'settings' in section_name:
                category = 'configuration'
            else:
                category = 'overview'
            
            print(f"ğŸ“ ã‚«ãƒ†ã‚´ãƒª: {category}")
            
            # Step 1: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            print("  1ï¸âƒ£ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ä¸­...")
            fetch_results = await fetcher.fetch([url], timeout=60)
            
            if not fetch_results or not fetch_results[0].get("success"):
                print(f"  âŒ å–å¾—å¤±æ•—: {url}")
                continue
            
            content = fetch_results[0].get("content", "")
            title = fetch_results[0].get("title", section_name)
            print(f"  âœ… {len(content)} æ–‡å­—ã‚’å–å¾—")
            
            # Step 2: æ§‹é€ ã‚’æŠ½å‡º
            print("  2ï¸âƒ£ éšå±¤æ§‹é€ ã‚’æŠ½å‡ºä¸­...")
            structure = await extractor.extract(
                content,
                extraction_config={
                    "granularity": "full_hierarchy",
                    "summarization": "detailed"
                }
            )
            
            headings_count = structure.get("total_headings", 0)
            confidence = structure.get("confidence_score", 0)
            print(f"  âœ… {headings_count} å€‹ã®è¦‹å‡ºã—ã‚’æŠ½å‡º (ä¿¡é ¼åº¦: {confidence:.2f})")
            
            # Step 3: é–¢é€£URLã‚’ç™ºè¦‹
            print("  3ï¸âƒ£ é–¢é€£URLç™ºè¦‹ä¸­...")
            discovered_urls = await discovery.discover(content, "docs.anthropic.com")
            internal_urls = [u for u in discovered_urls if u['relation_type'] == 'internal']
            print(f"  âœ… {len(internal_urls)} å€‹ã®å†…éƒ¨ãƒªãƒ³ã‚¯ã‚’ç™ºè¦‹")
            
            # Step 4: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
            print("  4ï¸âƒ£ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
            
            # éšå±¤æ§‹é€ ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            def format_headings(headings, indent=0):
                result = []
                for h in headings:
                    prefix = "  " * indent
                    result.append(f"{prefix}- **L{h['level']}**: {h['text']}")
                    if h.get('children'):
                        result.extend(format_headings(h['children'], indent + 1))
                return result
            
            structured_headings = structure.get("structured_headings", [])
            hierarchy_text = "\n".join(format_headings(structured_headings))
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
            context_body = f"""# {title}

## ğŸ“Œ æ¦‚è¦

**ã‚½ãƒ¼ã‚¹URL**: {url}
**æŠ½å‡ºæ—¥æ™‚**: {datetime.now().isoformat()}
**è¦‹å‡ºã—æ•°**: {headings_count}
**ä¿¡é ¼åº¦**: {confidence:.2f}

## ğŸ“Š éšå±¤æ§‹é€ 

{hierarchy_text if hierarchy_text else "éšå±¤æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

## ğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µãƒãƒªãƒ¼

{structure.get('content_summary', 'ã‚µãƒãƒªãƒ¼ãªã—')}

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯

"""
            # ä¸Šä½10å€‹ã®é–¢é€£URLã‚’è¿½åŠ 
            for url_info in internal_urls[:10]:
                context_body += f"- [{url_info['url'].split('/')[-1]}]({url_info['url']})\n"
            
            if not internal_urls:
                context_body += "é–¢é€£ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
            
            # æŠ½å‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¿½åŠ 
            entities = structure.get('extracted_entities', {})
            if entities.get('key_terms'):
                context_body += f"\n## ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n\n"
                context_body += ", ".join(entities['key_terms'][:20])
                context_body += "\n"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            file_path = f"{category}/{section_name}.md"
            result = await file_manager.execute(
                action="write_file",
                path=file_path,
                content={
                    "title": title,
                    "source_url": url,
                    "language": "ja",
                    "content_type": "documentation",
                    "extraction_confidence": confidence,
                    "hierarchy_levels": structure.get("hierarchy_levels", []),
                    "tags": ["claude-code", category, section_name],
                    "body": context_body
                }
            )
            
            if result.get("success"):
                print(f"  âœ… ä¿å­˜å®Œäº†: {file_path}")
                all_contexts.append({
                    "title": title,
                    "path": file_path,
                    "url": url,
                    "category": category,
                    "headings": headings_count,
                    "confidence": confidence
                })
            else:
                print(f"  âŒ ä¿å­˜å¤±æ•—: {result.get('error')}")
        
        # å…¨ä½“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ
        print("\n" + "="*60)
        print("ğŸ“š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”Ÿæˆä¸­...")
        
        index_body = """# Claude Code ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ - å®Œå…¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€Claude Codeå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸéšå±¤çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_category = {}
        for ctx in all_contexts:
            if ctx['category'] not in by_category:
                by_category[ctx['category']] = []
            by_category[ctx['category']].append(ctx)
        
        category_names = {
            'getting-started': 'ğŸš€ ã¯ã˜ã‚ã«',
            'building': 'ğŸ› ï¸ æ§‹ç¯‰',
            'deployment': 'ğŸš¢ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ',
            'administration': 'ğŸ”§ ç®¡ç†',
            'configuration': 'âš™ï¸ è¨­å®š',
            'reference': 'ğŸ“– ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹',
            'resources': 'ğŸ“š ãƒªã‚½ãƒ¼ã‚¹',
            'overview': 'ğŸ“‹ æ¦‚è¦'
        }
        
        for category, contexts in sorted(by_category.items()):
            index_body += f"\n### {category_names.get(category, category)}\n\n"
            for ctx in contexts:
                index_body += f"- [{ctx['title']}]({ctx['path']}) - "
                index_body += f"{ctx['headings']}å€‹ã®è¦‹å‡ºã— (ä¿¡é ¼åº¦: {ctx['confidence']:.2f})\n"
        
        index_body += f"""

## ğŸ“Š çµ±è¨ˆæƒ…å ±

- **ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°**: {len(all_contexts)}
- **ç·è¦‹å‡ºã—æ•°**: {sum(ctx['headings'] for ctx in all_contexts)}
- **å¹³å‡ä¿¡é ¼åº¦**: {sum(ctx['confidence'] for ctx in all_contexts) / len(all_contexts) if all_contexts else 0:.2f}
- **æŠ½å‡ºæ—¥æ™‚**: {datetime.now().isoformat()}

## ğŸ” ä½¿ç”¨æ–¹æ³•

å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã£ã¦ã„ã¾ã™ï¼š

1. **YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼**: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨éšå±¤æƒ…å ±
2. **éšå±¤æ§‹é€ **: L1ã€œL6ãƒ¬ãƒ™ãƒ«ã®è¦‹å‡ºã—æ§‹é€ 
3. **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µãƒãƒªãƒ¼**: ä¸»è¦å†…å®¹ã®è¦ç´„
4. **é–¢é€£ãƒªãƒ³ã‚¯**: ç™ºè¦‹ã•ã‚ŒãŸé–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
5. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: æŠ½å‡ºã•ã‚ŒãŸé‡è¦ç”¨èª

ã“ã‚Œã‚‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Claude Codeã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ä½œæˆã€
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ˜ãƒ«ãƒ—ãƒœãƒƒãƒˆãªã©ã®æ§‹ç¯‰ã«æ´»ç”¨ã§ãã¾ã™ã€‚
"""
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        await file_manager.execute(
            action="write_file",
            path="README.md",
            content={
                "title": "Claude Code Documentation Context Index",
                "generated_at": datetime.now().isoformat(),
                "total_documents": len(all_contexts),
                "body": index_body
            }
        )
        
        print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”Ÿæˆå®Œäº†")
        
        # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        print("\n" + "="*60)
        print("âœ¨ æŠ½å‡ºå®Œäº†ï¼")
        print("="*60)
        print(f"\nğŸ“Š çµæœã‚µãƒãƒªãƒ¼:")
        print(f"  - å‡¦ç†ã—ãŸURL: {len(all_contexts)}/{len(claude_docs_urls)}")
        print(f"  - ç”Ÿæˆã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {len(all_contexts)}")
        print(f"  - å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: generated_contexts/claude-code-full/")
        print(f"  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: generated_contexts/claude-code-full/README.md")
        
    finally:
        await fetcher.close()


if __name__ == "__main__":
    asyncio.run(extract_claude_code_docs())